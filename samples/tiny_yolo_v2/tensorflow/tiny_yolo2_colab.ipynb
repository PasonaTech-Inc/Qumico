{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tiny_yolo_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_dtOF1yCZCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "# Google Colabのアカウント作って登録する\n",
        "# FileをクリックしてNew python3 notebookを選ぶ\n",
        "# New　Python3notebook　クリックする\n",
        "\n",
        "# GPUで動き設定\n",
        "# runtime(メニューのボタン)　クリックして change runtime type　クリックして　GPUに設定する\n",
        "\n",
        "# google　colabからマウントする\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# authorization code取得して入力する（enterを押すとマウント完了）\n",
        "\n",
        "# 出力メッセージ:\n",
        "# Enter your authorization code:\n",
        "# ··········\n",
        "# Mounted at /content/gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQMrZE8xCgxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gitからプロジェクトをクローンする\n",
        "! git clone https://github.com/PasonaTech-Inc/Qumico.git \"/content/gdrive/My Drive/Qumico\"\n",
        "# 一度クローンした場合は　\n",
        "# 'fatal: destination path '/content/gdrive/My Drive/Qumico' already exists and is not an empty directory.'って表示する"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1if4WRbeCnbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pythonpathの環境変数設定\n",
        "import os                                                                                                             \n",
        "os.environ['PYTHONPATH'] += \":/content/gdrive/My Drive/Qumico\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTfKG95hxG_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pythonpath設定された\n",
        "! echo $PYTHONPATH\n",
        "# 出力メッセージ:　/env/python:/content/gdrive/My Drive/Qumico"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNQsikegxtLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ディレクトリを移動する\n",
        "%cd /content/gdrive/My Drive/Qumico\n",
        "# ディレクトリ確認する。\n",
        "# 出力メッセージ: /content/gdrive/My Drive/Qumico"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F3fpJUiHMKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs_bqCd_CpHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 必要なライブラリをインストールする\n",
        "! pip install -r requirements.txt\n",
        "! pip install tensorflow-gpu==1.13.2 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjAae7G_KURp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#path変わったため、writefileで実行する\n",
        "%%writefile samples/tiny_yolo_v2/tensorflow/tiny_yolo2_train.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from samples.tiny_yolo_v2.tensorflow.tiny_yolo2_model import TINY_YOLO_v2\n",
        "import samples.utils.pre_process_tool as list_reader\n",
        "from samples.utils.annotation_dataset_tool import AnnotationDatasetTool\n",
        "from samples.utils.data_augument_tool import (Transform, Sequence,RandomHorizontalFlip,RandomScale,RandomRotate,\n",
        "                                         RandomTranslate, RandomHSV, RandomShear)\n",
        "from qumico.Qumico import Qumico\n",
        "#%% 変数変更どころ%%\n",
        "import os\n",
        "\n",
        "\n",
        "def retrain(model, train_data, ckpt_file, epochs, batch_size, save_flag=True):\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    pb_file = None\n",
        "    data_size = train_data.total_size\n",
        "    total_batch = data_size // batch_size\n",
        "\n",
        "    with tf.Session(graph=model.graph) as sess_train:\n",
        "        model.saver.restore(sess_train, ckpt_file)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            total_class_loss = 0\n",
        "            total_obj_loss = 0\n",
        "            total_coord_loss = 0\n",
        "            for i in range(total_batch):\n",
        "                batch_x, batch_y, _, _ = train_data.next_batch_once(batch_size=batch_size)\n",
        "                y_true, y_mask, y_true_no_grid = model.pre_process_true_boxes_normal(batch_y, grid_w=model.grid_w, grid_h=model.grid_h)\n",
        "                \n",
        "\n",
        "                _, output, loss, class_loss, obj_loss, coord_loss = sess_train.run(\n",
        "                    [model.train_op, model.output, model.total_loss, model.class_loss, model.object_loss, model.coord_loss],\n",
        "                    feed_dict={model.inputs: batch_x, model.y_true: y_true, model.y_mask: y_mask, model.y_true_nogrid: y_true_no_grid})\n",
        "\n",
        "\n",
        "\n",
        "                total_loss += loss\n",
        "                total_class_loss += class_loss\n",
        "                total_obj_loss += obj_loss\n",
        "                total_coord_loss += coord_loss\n",
        "                print(\"=\" * 3, \"epoch:\", epoch + 1, \" - batch\", i + 1, \"/\", total_batch, \"=\" * 3)\n",
        "\n",
        "            print(\"total loss : \", total_loss / data_size, \" class loss : \", total_class_loss / data_size,\n",
        "                  \" obj loss : \", total_obj_loss / data_size, \" coord_loss : \", total_coord_loss / data_size)\n",
        "\n",
        "\n",
        "        if save_flag:\n",
        "            ckpt_file = \"model/tiny_yolo2.ckpt\"\n",
        "            pb_path = \"model\"\n",
        "            pb_name = \"tiny_yolo2.pb\"\n",
        "            pb_file = pb_path + \"/\" + pb_name\n",
        "            model.saver.save(sess_train, ckpt_file)\n",
        "            model.pb_saver.write_graph(sess_train.graph, pb_path, pb_name, as_text=False)\n",
        "\n",
        "    return ckpt_file, pb_file\n",
        "\n",
        "def train(model, train_data, epochs, batch_size, save_flag=True):\n",
        "    tf.reset_default_graph()\n",
        "    ckpt_file = None\n",
        "    pb_file = None\n",
        "    data_size = train_data.total_size\n",
        "    total_batch = data_size // batch_size\n",
        "\n",
        "    with tf.Session(graph=model.graph) as sess_train:\n",
        "        sess_train.run(model.init)\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            total_class_loss = 0\n",
        "            total_obj_loss = 0\n",
        "            total_coord_loss = 0\n",
        "            for i in range(total_batch):\n",
        "                batch_x, batch_y, _, _ = train_data.next_batch_once(batch_size=batch_size)\n",
        "                y_true, y_mask, y_true_no_grid = model.pre_process_true_boxes_normal(batch_y, grid_w=model.grid_w, grid_h=model.grid_h)\n",
        "\n",
        "                _, output, loss, class_loss, obj_loss, coord_loss = sess_train.run(\n",
        "                    [model.train_op, model.output, model.total_loss, model.class_loss, model.object_loss, model.coord_loss],\n",
        "                    feed_dict={model.inputs: batch_x, model.y_true: y_true, model.y_mask: y_mask, model.y_true_nogrid: y_true_no_grid})\n",
        "\n",
        "\n",
        "\n",
        "                total_loss += loss\n",
        "                total_class_loss += class_loss\n",
        "                total_obj_loss += obj_loss\n",
        "                total_coord_loss += coord_loss\n",
        "                print(\"=\" * 3, \"epoch:\", epoch + 1, \" - batch\", i + 1, \"/\", total_batch, \"=\" * 3)\n",
        "\n",
        "            print(\"total loss : \", total_loss / data_size, \" class loss : \", total_class_loss / data_size,\n",
        "                  \" obj loss : \", total_obj_loss / data_size, \" coord_loss : \", total_coord_loss / data_size)\n",
        "\n",
        "\n",
        "        if save_flag:\n",
        "            ckpt_file = \"model/tiny_yolo2.ckpt\"\n",
        "            pb_path = \"model\"\n",
        "            pb_name = \"tiny_yolo2.pb\"\n",
        "            pb_file = pb_path + \"/\" + pb_name\n",
        "            model.saver.save(sess_train, ckpt_file)\n",
        "            model.pb_saver.write_graph(sess_train.graph, pb_path, pb_name, as_text=False)\n",
        "\n",
        "    return ckpt_file, pb_file\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # クラス　ラベル\n",
        "    voc2007_classes = ['chair', 'bird', 'sofa', 'bicycle', 'cat', 'motorbike', 'bus', 'boat', 'sheep', 'bottle', 'cow',\n",
        "                       'person', 'horse', 'diningtable', 'pottedplant', 'aeroplane', 'car', 'train', 'dog', 'tvmonitor']\n",
        "    # クラスの数　Ont-Hot表現用パラメータ\n",
        "    num_classes = len(voc2007_classes)\n",
        "\n",
        "    #%% 変数変更どころ%%\n",
        "    root_path = \"/content/gdrive/My Drive/Qumico/samples/tiny_yolo_v2/tensorflow\"       \n",
        "    data_path = os.path.join(root_path, \"data\")\n",
        "\n",
        "    #%% 変数変更どころ%%\n",
        "    data_list_path = os.path.join(data_path, \"JPEGImages\")\n",
        "    label_list_path = os.path.join(data_path, \"Annotations\")\n",
        "\n",
        "    data_list = np.asarray(list_reader.get_data_path_list(data_list_path)[:])\n",
        "    label_list = np.asarray(list_reader.get_data_path_list(label_list_path)[:])\n",
        "\n",
        "    # Data Augument\n",
        "    transformer = Sequence([RandomHorizontalFlip(), RandomScale(0.3, diff=True),\n",
        "                            RandomHSV(hue=50, saturation=50, brightness=50), RandomShear(),RandomTranslate(diff=True)])\n",
        "\n",
        "    # 読み方、バッチ処理などを設定し、データを供給するツール設定する\n",
        "    annotation_dataset_tool = AnnotationDatasetTool(training_flag=True, data_list=data_list, label_list=label_list,\n",
        "                                                    category_class=voc2007_classes, one_hot_classes=num_classes,\n",
        "                                                    resize_flag=True, target_h=416, target_w=416,\n",
        "                                                    label_file_type=\"voc_xml\", format=\"NCHW\", data_rescale=True, label_resclar=True,\n",
        "                                                    transformer=transformer)\n",
        "\n",
        "    # バッチサイズ\n",
        "    batch_size = 1\n",
        "    epoch_num = 2\n",
        "    total_size = annotation_dataset_tool.total_size\n",
        "\n",
        "    range_size = int(total_size / batch_size)\n",
        "    # load model\n",
        "    tiny_yolo_2 = TINY_YOLO_v2(height=416, width=416, output_op_name=\"output\", num_classes=20, is_train=True,\n",
        "                               batch_size=batch_size)\n",
        "\n",
        "    # train and save ckpt pb file\n",
        "    # ====train==================================================================================================\n",
        "    ckpt_file, pb_file = train(tiny_yolo_2, annotation_dataset_tool, epoch_num, batch_size, save_flag=True)\n",
        "    # ====retain============================================================================================\n",
        "    #%% 変数変更どころ%%\n",
        "    ckpt_file = os.path.join(root_path, \"model/tiny_yolo2.ckpt\")\n",
        "    # pb_file= \"model/tiny_yolo2.pb\"     \n",
        "    #ckpt_file, pb_file = retrain(tiny_yolo_2, annotation_dataset_tool, ckpt_file, epoch_num, batch_size, save_flag=True)\n",
        "    # ======================================================================================================\n",
        "\n",
        "    print(\"ckpt_file\", ckpt_file)\n",
        "    print(\"pb_file\", pb_file)\n",
        "\n",
        "    # prepare Qumico Convertor\n",
        "    converter = Qumico()\n",
        "    converter.conv_tf_to_onnx(output_path=\"onnx\", model_name=\"tiny_yolo_2\", output_op_name=\"output\",\n",
        "                              cache_path=\"model\", ckpt_file=ckpt_file, pb_file=pb_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndw443bMBriC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatcの実行権限与える\n",
        "!chmod +x \"/content/gdrive/My Drive/Qumico/external/flatbuffers/flatc\"\n",
        "!ls -la \"/content/gdrive/My Drive/Qumico/external/flatbuffers/flatc\"\n",
        "# 出力メッセージ:　rwx------ 1 root root 3771528 Dec 23 01:27 '/content/gdrive/My Drive/Qumico/external/flatbuffers/flatc'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnl3QrDse65C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tiny_yolo_v2のonnxファイル作る\n",
        "! python samples/tiny_yolo_v2/tensorflow/tiny_yolo2_train.py\n",
        "# 出力メッセージ:　 \n",
        "# onnx/tiny_yolo_2.onnxを作成しました。"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFMc5jhPExaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# out_cのフォルダ作る(デフォルトはFalse)\n",
        "! python samples/tiny_yolo_v2/tensorflow/gen_c.py\n",
        "# 出力メッセージ:  　\n",
        "# Cソースを生成しました。出力先: out_c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3h36Bevj7zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#一旦qumico.so削除する\n",
        "! rm samples/tiny_yolo_v2/tensorflow/out_c/qumico.so\n",
        "#削除チェック\n",
        "! ls samples/tiny_yolo_v2/tensorflow/out_c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC4-4CG6EO-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#known_issues フォルダ　の何にあるbatchnormalization.cとmaxpool.c\n",
        "#二つのファクタをout_cフォルダのlibにコピーしてまたqumico.cをcompileする\n",
        "! gcc -c -fPIC samples/tiny_yolo_v2/tensorflow/out_c/qumico.c -o file.o\n",
        "! gcc file.o -shared -o samples/tiny_yolo_v2/tensorflow/out_c/qumico.so\n",
        "#qumico.so チェック\n",
        "! ls samples/tiny_yolo_v2/tensorflow/out_c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb_EBZ4KLJmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ministデータ十個取得、　トレーニングしたモデルで推論した結果引き出す\n",
        "# (notebookでopen_cvから画像出力できないため、代わりにipythonで出力することになります)\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from samples.utils.annotation_dataset_tool import AnnotationDatasetTool\n",
        "from samples.tiny_yolo_v2.tensorflow.tiny_yolo2_infer import infer\n",
        "from samples.tiny_yolo_v2.tensorflow import tiny_yolo2_infer\n",
        "import samples.utils.pre_process_tool as list_reader\n",
        "from samples.tiny_yolo_v2.tensorflow.tiny_yolo2_model import TINY_YOLO_v2\n",
        "\n",
        "voc2007_classes = ['chair', 'bird', 'sofa', 'bicycle', 'cat', 'motorbike', 'bus', 'boat', 'sheep', 'bottle', 'cow',\n",
        "                       'person', 'horse', 'diningtable', 'pottedplant', 'aeroplane', 'car', 'train', 'dog', 'tvmonitor']\n",
        "\n",
        "num_classes = len(voc2007_classes)\n",
        "root_path = \"/content/gdrive/My Drive/Qumico/samples/tiny_yolo_v2/tensorflow\"\n",
        "data_path = os.path.join(root_path, \"data\")\n",
        "data_list_path = os.path.join(data_path, \"JPEGImages\")\n",
        "label_list_path = os.path.join(data_path, \"Annotations\")\n",
        "pic_num = 0\n",
        "data_list = np.asarray(list_reader.get_data_path_list(data_list_path)[pic_num:pic_num+1])\n",
        "label_list = np.asarray(list_reader.get_data_path_list(label_list_path)[pic_num:pic_num+1])\n",
        "annotation_dataset_tool = AnnotationDatasetTool(training_flag=True, data_list=data_list, label_list=label_list,\n",
        "                                                    category_class=voc2007_classes, one_hot_classes=num_classes,\n",
        "                                                    resize_flag=True, target_h=416, target_w=416,\n",
        "                                                    label_file_type=\"voc_xml\", format=\"NCHW\", data_rescale=True, label_resclar=True)\n",
        "batch_size = 1\n",
        "tiny_yolo2_model = TINY_YOLO_v2(output_op_name=\"output\", num_classes=20, is_train=False, width=416, height=416)\n",
        "ckpt_file = os.path.join(root_path, \"model/tiny_yolo2_backup.ckpt\")\n",
        "print(ckpt_file)\n",
        "res = tiny_yolo2_infer.infer(tiny_yolo2_model, annotation_dataset_tool, ckpt_file, voc2007_classes, batch_size, to_draw=False)\n",
        "print(res)\n",
        " \n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "w, h = 300, 300\n",
        "data = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "data[0:256, 0:256] = [255, 0, 0] # red patch in upper left\n",
        "img = Image.fromarray(res)\n",
        "display(img)\n",
        "\n",
        "# Sunflower"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeMr5zahSIzu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ministデータ十個取得、　トレーニングしたモデルで推論した結果引き出す\n",
        "# (notebookでopen_cvから画像出力できないため、代わりにipythonで出力することになります)\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from samples.utils.annotation_dataset_tool import AnnotationDatasetTool\n",
        "from samples.tiny_yolo_v2.tensorflow.tiny_yolo2_infer_c import infer_c\n",
        "from samples.tiny_yolo_v2.tensorflow import tiny_yolo2_infer_c\n",
        "import samples.utils.pre_process_tool as list_reader\n",
        "from samples.tiny_yolo_v2.tensorflow.tiny_yolo2_model import TINY_YOLO_v2\n",
        "\n",
        "voc2007_classes = ['chair', 'bird', 'sofa', 'bicycle', 'cat', 'motorbike', 'bus', 'boat', 'sheep', 'bottle', 'cow',\n",
        "                       'person', 'horse', 'diningtable', 'pottedplant', 'aeroplane', 'car', 'train', 'dog', 'tvmonitor']\n",
        "\n",
        "                       \n",
        "num_classes = len(voc2007_classes)\n",
        "root_path = '/content/gdrive/My Drive/Qumico/samples/tiny_yolo_v2/tensorflow'\n",
        "c_path = os.path.join(root_path, \"out_c\", \"qumico.so\") \n",
        "data_path = os.path.join(root_path, \"data\")\n",
        "data_list_path = os.path.join(data_path, \"JPEGImages\")\n",
        "label_list_path = os.path.join(data_path, \"Annotations\")\n",
        "pic_num = 0\n",
        "data_list = np.asarray(list_reader.get_data_path_list(data_list_path)[pic_num:pic_num+1])\n",
        "label_list = np.asarray(list_reader.get_data_path_list(label_list_path)[pic_num:pic_num+1])\n",
        "annotation_dataset_tool = AnnotationDatasetTool(training_flag=True, data_list=data_list, label_list=label_list,\n",
        "                                                    category_class=voc2007_classes, one_hot_classes=num_classes,\n",
        "                                                    resize_flag=True, target_h=416, target_w=416,\n",
        "                                                    label_file_type=\"voc_xml\", format=\"NCHW\", data_rescale=True, label_resclar=True)\n",
        "batch_size = 1\n",
        "tiny_yolo2_model = TINY_YOLO_v2(output_op_name=\"output\", num_classes=20, is_train=False, width=416, height=416)\n",
        "res = tiny_yolo2_infer_c.infer_c(tiny_yolo2_model, annotation_dataset_tool, c_path, voc2007_classes, batch_size, to_draw=True)\n",
        "print(res)\n",
        " \n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from IPython.display import display\n",
        "w, h = 300, 300\n",
        "data = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "data[0:256, 0:256] = [255, 0, 0] # red patch in upper left\n",
        "img = Image.fromarray(res)\n",
        "display(img)\n",
        "\n",
        "# Sunflower"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlaSELFrPWG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ディレクトリ移します。\n",
        "%cd samples/tiny_yolo_v2/tensorflow/\n",
        "# ディレクトリ確認します。\n",
        "# 出力メッセージ /content/gdrive/My Drive/Qumico/samples/tiny_yolo_v2/tensorflow/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uoulIIBzpOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# out_cフォルダ存在するがどうか確認する\n",
        "! ls \n",
        "# data\t     model  __pycache__  tiny_yolo2_infer_c.py\ttiny_yolo2_train.py\n",
        "# gen_c.py     onnx   testfile\t tiny_yolo2_infer.py\n",
        "# known_issue  out_c  testnum.py\t tiny_yolo2_model.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62WyZF4ArN81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# qumico.so存在するがどうか確認する\n",
        "! ls out_c\n",
        "# 出力メッセージ:\n",
        "# include  initializers  lib  numpy.c  qumico.c  qumico.so"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ktjej8pdYNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# out_c file zipして出力する \n",
        "!zip -r '/content/gdrive/My Drive/out_c.zip' out_c  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
